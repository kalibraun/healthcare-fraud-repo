{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df76a580",
   "metadata": {},
   "source": [
    " Objective: Train a model to detect fraudulent providers with suspiciously high claim volumes in short durations using inpatient + outpatient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9298a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load outpatient data \n",
    "# Replace these paths with the correct file paths on your machine\n",
    "df_fraud = pd.read_csv(\"/Users/kalibraun/dev/healthcare/fraudTrain.csv.xls\")\n",
    "df_in = pd.read_csv(\"/Users/kalibraun/dev/healthcare/inpatientData.csv\")\n",
    "df_out = pd.read_csv(\"/Users/kalibraun/dev/healthcare/outpatientData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1706e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at df_fraud, should be yes and no in potentialfraud column\n",
    "print(df_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab36447",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_in.columns)\n",
    "print(df_out.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9689dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df_fraud from bool to int\n",
    "df_fraud[\"PotentialFraud\"] = df_fraud[\"PotentialFraud\"].map({\"Yes\": 1, \"No\": 0})\n",
    "print(df_fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e2e4a0",
   "metadata": {},
   "source": [
    "Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0529d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create claim duration column\n",
    "# convert date columns to datetime format \n",
    "df_in[\"ClaimStartDt\"] = pd.to_datetime(df_in[\"ClaimStartDt\"])\n",
    "df_in[\"ClaimEndDt\"] = pd.to_datetime(df_in[\"ClaimEndDt\"])\n",
    "\n",
    "df_out[\"ClaimStartDt\"] = pd.to_datetime(df_out[\"ClaimStartDt\"])\n",
    "df_out[\"ClaimEndDt\"] = pd.to_datetime(df_out[\"ClaimEndDt\"])\n",
    "\n",
    "# create new duration column in days\n",
    "df_in[\"ClaimDuration\"] = (df_in[\"ClaimEndDt\"] - df_in[\"ClaimStartDt\"]).dt.days\n",
    "df_out[\"ClaimDuration\"] = (df_out[\"ClaimEndDt\"] - df_out[\"ClaimStartDt\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72297488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate inpatient data by provider \n",
    "in_agg = df_in.groupby(\"Provider\").agg(\n",
    "    InpatientClaimCount=(\"Provider\", \"count\"),\n",
    "    InpatientTotalReimbursed=(\"InscClaimAmtReimbursed\", \"sum\"),\n",
    "    InpatientAvgDuration=(\"ClaimDuration\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "# Aggregate outpatient data by provider\n",
    "out_agg = df_out.groupby(\"Provider\").agg(\n",
    "    OutpatientClaimCount=(\"Provider\", \"count\"),\n",
    "    OutpatientTotalReimbursed=(\"InscClaimAmtReimbursed\", \"sum\"),\n",
    "    OutpatientAvgDuration=(\"ClaimDuration\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "# Merge inpatient + outpatient\n",
    "provider_features = pd.merge(in_agg, out_agg, on=\"Provider\", how=\"outer\").fillna(0)\n",
    "\n",
    "# Merge with fraud labels\n",
    "df_fraud[\"PotentialFraud\"] = df_fraud[\"PotentialFraud\"]\n",
    "df = pd.merge(provider_features, df_fraud, on=\"Provider\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d069f7",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd22be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'InpatientClaimCount', 'InpatientTotalReimbursed', 'InpatientAvgDuration',\n",
    "    'OutpatientClaimCount', 'OutpatientTotalReimbursed', 'OutpatientAvgDuration'\n",
    "]\n",
    "X = df[features]\n",
    "y = df[\"PotentialFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"XGBoost Accuracy:\", xgb_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f59f57",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f2feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Not Fraud\", \"Fraud\"])\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Fraud\", \"Fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4224177e",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3232f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Importance\n",
    "importances = pd.Series(xgb_clf.feature_importances_, index=features)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "importances.sort_values().plot(kind=\"barh\", color=\"steelblue\")\n",
    "plt.title(\"XGBoost Feature Importances\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot: Claim Volume vs Fraud Probability\n",
    "sns.set(style = \"whitegrid\")\n",
    "\n",
    "# Get fraud probabilities from the model\n",
    "df[\"FraudProbability\"] = xgb_clf.predict_proba(X)[:, 1]  # Probability of class 1 (fraud)\n",
    "\n",
    "# create totalcaimcount column\n",
    "df[\"TotalClaimCount\"] = df[\"InpatientClaimCount\"] + df[\"OutpatientClaimCount\"]\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x= \"TotalClaimCount\",  \n",
    "    y=\"FraudProbability\",\n",
    "    hue=\"PotentialFraud\",\n",
    "    palette={0: \"green\", 1: \"red\"}, # geen = no fraud, red = fraud\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "plt.title(\"Claim Volume vs. Predicted Fraud Probability\")\n",
    "plt.xlabel(\"Total Claim Count (Inpatient + Outpatient)\")\n",
    "plt.ylabel(\"Predicted Fraud Probability\")\n",
    "plt.legend(title=\"Actual Fraud\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b89f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highlight top N providers with highest fraud probability \n",
    "\n",
    "# Get top N riskiest providers\n",
    "top_n = 10\n",
    "top_providers = df.sort_values(\"FraudProbability\", ascending=False).head(top_n)\n",
    "\n",
    "# Base scatter plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"TotalClaimCount\",\n",
    "    y=\"FraudProbability\",\n",
    "    hue=\"PotentialFraud\",\n",
    "    palette={0: \"green\", 1: \"red\"},\n",
    "    alpha=0.5,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Highlight top N\n",
    "sns.scatterplot(\n",
    "    data=top_providers,\n",
    "    x=\"TotalClaimCount\",\n",
    "    y=\"FraudProbability\",\n",
    "    color=\"black\",\n",
    "    s=100,\n",
    "    marker=\"X\",\n",
    "    label=f\"Top {top_n} Risky Providers\"\n",
    ")\n",
    "\n",
    "# Annotate provider IDs\n",
    "for _, row in top_providers.iterrows():\n",
    "    plt.text(\n",
    "        row[\"TotalClaimCount\"] + 1,  # Slight offset\n",
    "        row[\"FraudProbability\"],\n",
    "        row[\"Provider\"],\n",
    "        fontsize=9,\n",
    "        color=\"black\"\n",
    "    )\n",
    "\n",
    "plt.title(\"Claim Volume vs. Predicted Fraud Probability (Top Risky Providers Highlighted)\")\n",
    "plt.xlabel(\"Total Claim Count\")\n",
    "plt.ylabel(\"Predicted Fraud Probability\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1734307",
   "metadata": {},
   "source": [
    "Black \"X\" markers show the highest-risk providers.\n",
    "Their IDs are annotated for clarity.\n",
    "You can change top_n to highlight more/less risky ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf251b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly Version: Interactive Scatter Plot\n",
    "import plotly.express as px\n",
    "\n",
    "# Make sure TotalClaimCount is calculated\n",
    "df[\"TotalClaimCount\"] = df[\"InpatientClaimCount\"] + df[\"OutpatientClaimCount\"]\n",
    "\n",
    "# Optional: Label fraud class as string for prettier legend\n",
    "df[\"FraudLabel\"] = df[\"PotentialFraud\"].map({0: \"Not Fraud\", 1: \"Fraud\"})\n",
    "\n",
    "# Create interactive scatter plot\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"TotalClaimCount\",\n",
    "    y=\"FraudProbability\",\n",
    "    color=\"FraudLabel\",\n",
    "    hover_data=[\"Provider\", \"TotalClaimCount\", \"FraudProbability\"],\n",
    "    title=\"Interactive: Claim Volume vs Predicted Fraud Probability\",\n",
    "    labels={\"TotalClaimCount\": \"Total Claims\", \"FraudProbability\": \"Fraud Probability\"},\n",
    "    color_discrete_map={\"Fraud\": \"red\", \"Not Fraud\": \"green\"},\n",
    "    opacity=0.6\n",
    ")\n",
    "\n",
    "# Highlight top N risky providers\n",
    "top_n = 10\n",
    "top_providers = df.nlargest(top_n, \"FraudProbability\")\n",
    "\n",
    "fig.add_scatter(\n",
    "    x=top_providers[\"TotalClaimCount\"],\n",
    "    y=top_providers[\"FraudProbability\"],\n",
    "    mode=\"markers+text\",\n",
    "    marker=dict(size=12, color=\"black\", symbol=\"x\"),\n",
    "    text=top_providers[\"Provider\"],\n",
    "    textposition=\"top center\",\n",
    "    name=f\"Top {top_n} Risky Providers\"\n",
    ")\n",
    "\n",
    "fig.update_layout(legend_title_text=\"Actual Fraud Label\", height=600)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed94bb4",
   "metadata": {},
   "source": [
    "Ways to improving model \n",
    "- Feature Engineering \n",
    "- Class Weights or Sampling\n",
    "- Hyperparameter Tuning\n",
    "- More Evaluation Metrics\n",
    "- Model Stacking / Blending\n",
    "- SHAP or Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap - This can reveal what makes providers look suspicious \n",
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb_clf)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1159a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more evaluation metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "y_proba = xgb_clf.predict_proba(X_test)[:, 1] # predicted probabilities\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve plot\n",
    "# the closer the curve is to the top left corner, the better your model is\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get false positive rate, true positive rate, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\", color='darkorange', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')  # Diagonal baseline\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
